# GCP LakeHouse - Tutoriel BigQuery

Ce repository contient un tutoriel complet pour importer des fichiers CSV depuis Google Cloud Storage vers BigQuery dans un environnement d'entreprise.

## ğŸ“‹ Contenu

- **[tutoriel_import_csv_gcs_bigquery.md](./tutoriel_import_csv_gcs_bigquery.md)** - Guide complet d'import CSV vers BigQuery avec orchestration Airflow

## ğŸ¯ Public cible

- Data Engineers
- Data Analysts
- Ã‰quipes travaillant sur la stack GCP BigQuery

## ğŸ¢ Contexte entreprise

- **Environnement** : GCP Console (DEV)
- **Orchestrateur** : Apache Airflow
- **Stack** : BigQuery full stack
- **Objectif** : Pipeline de donnÃ©es automatisÃ© et schedulÃ©

## ğŸš€ Utilisation

1. Suivez le tutoriel Ã©tape par Ã©tape dans [tutoriel_import_csv_gcs_bigquery.md](./tutoriel_import_csv_gcs_bigquery.md)
2. Adaptez les configurations Ã  votre environnement
3. ImplÃ©mentez le pipeline Airflow selon vos besoins

## ğŸ“Š Exemple de donnÃ©es

Le tutoriel utilise un fichier CSV d'exemple avec des donnÃ©es d'employÃ©s contenant :
- Informations personnelles (nom, prÃ©nom, email, Ã¢ge)
- DonnÃ©es gÃ©ographiques (ville, coordonnÃ©es)
- Informations professionnelles (salaire, dÃ©partement, statut)

## ğŸ”§ PrÃ©requis

- AccÃ¨s Ã  la GCP Console
- Fichier CSV dans Google Cloud Storage
- Permissions BigQuery et GCS appropriÃ©es
- Apache Airflow configurÃ© (Cloud Composer recommandÃ©)

## ğŸ“š Ressources

- [Bonnes pratiques pour charger, transformer et exporter des donnÃ©es BigQuery](https://cloud.google.com/bigquery/docs/load-transform-export-intro?hl=fr)
- [Documentation BigQuery](https://cloud.google.com/bigquery/docs)
- [Documentation Apache Airflow](https://airflow.apache.org/docs/)
- [Google Cloud Composer](https://cloud.google.com/composer/docs)