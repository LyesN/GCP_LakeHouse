# Architecture Lakehouse Aliment√© avec Fichiers

Cette documentation pr√©sente l'architecture et l'impl√©mentation pratique du framework GCP Data Lakehouse pour l'alimentation de donn√©es par fichiers, bas√©e sur l'architecture **m√©daillon √©tendue** avec 4 couches.

## Vue d'Ensemble Architecture

![Architecture Pipeline Data](Architecture-pipline-data.png)

*Architecture g√©n√©rale du framework GCP Data Lakehouse avec l'approche m√©daillon √©tendue : **RAW ‚Üí Bronze ‚Üí Silver ‚Üí Gold***

## Architecture M√©daillon GCP √âtendue

L'architecture suit le pattern **m√©daillon √©tendu** avec 4 couches, impl√©ment√© avec les services GCP :

### üìÅ **Couche RAW** (Landing Zone)
- **Stockage** : Google Cloud Storage (bucket landing)
- **R√¥le** : Zone d'atterrissage des fichiers sources externes
- **Formats** : Tous formats natifs (CSV, JSON, Parquet, XML, etc.)
- **Caract√©ristiques** :
  - Fichiers sources "as-is" depuis syst√®mes externes
  - Aucune transformation ni validation
  - R√©tention temporaire (7-30 jours)
  - Point d'entr√©e unique pour toutes les sources

### ü•â **Couche BRONZE** (Donn√©es Historis√©es)
- **Stockage** : BigQuery tables avec m√©tadonn√©es d'ingestion
- **R√¥le** : Historisation compl√®te avec tra√ßabilit√©
- **Technologie** : Tables BigQuery partitionn√©es par date d'ingestion
- **Caract√©ristiques** :
  - Ingestion compl√®te des donn√©es RAW dans BigQuery
  - **M√©tadonn√©es automatiques** : `ingestion_date`, `source_file`, `file_hash`
  - Historique immutable et auditable
  - Sch√©ma flexible avec d√©tection automatique
  - Partitioning par date pour performance

### ü•à **Couche SILVER** (Donn√©es Nettoy√©es)
- **Stockage** : BigQuery avec tables ou vues
- **R√¥le** : Interface d'acc√®s structur√© et nettoy√© aux donn√©es Bronze
- **Technologie** : Tables externes BigQuery ou vues sur Bronze
- **Caract√©ristiques** :
  - Transformation et nettoyage des donn√©es Bronze
  - Validation de qualit√© et conformit√© sch√©ma
  - D√©duplication et standardisation
  - Int√©gration native avec Dataform

### ü•á **Couche GOLD** (Donn√©es Business-Ready)
- **Stockage** : BigQuery avec tables mat√©rialis√©es optimis√©es
- **R√¥le** : Donn√©es enrichies, agr√©g√©es et pr√™tes pour l'analytique
- **Technologie** : Tables BigQuery optimis√©es avec SLA
- **Caract√©ristiques** :
  - Transformations m√©tier et r√®gles business
  - Agr√©gations et m√©triques calcul√©es
  - Performance optimis√©e (clustering, partitioning)
  - Donn√©es certifi√©es pour le reporting

## Exemple Concret : Workflow Pattern 1 avec Cloud Composer

![Exemple Implementation Pattern 1](Architecture-pipline-data-exemple-implementation.png)

*Workflow d√©taill√© d'ingestion CSV orchestr√© par Cloud Composer suivant l'architecture m√©daillon*

### Flux de Donn√©es Orchestr√© (4 Couches)

Le diagramme montre un **workflow Cloud Composer** complet adapt√© pour l'architecture 4-couches :

#### 1. **V√©rification Landing Zone (RAW)**
- **Action** : "V√©rifier que les fichiers sont disponibles"
- **Couche** : RAW (Cloud Storage landing)
- **Contr√¥les** : Pr√©sence fichiers, permissions, int√©grit√©
- **Sortie** : Notification vers Pub/Sub en cas d'erreur

#### 2. **Contr√¥le Qualit√© Sources**
- **Action** : "V√©rifier la qualit√© des fichiers (en-t√™te, s√©parateur...)"
- **Couche** : Validation RAW avant ingestion
- **Contr√¥les** : Headers, d√©limiteurs, encodage, taille, format
- **Sortie** : Logs applicatifs vers monitoring

#### 3. **Ingestion Bronze avec M√©tadonn√©es**
- **Action** : "Ing√©rer les fichiers RAW vers Bronze BigQuery"
- **Source** : Cloud Storage (RAW)
- **Destination** : BigQuery tables Bronze avec m√©tadonn√©es
- **Transformations** :
  - Ajout `ingestion_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP()`
  - Ajout `source_file STRING` (chemin complet)
  - Ajout `file_hash STRING` (pour d√©duplication)
  - Ajout `batch_id STRING` (pour tra√ßabilit√©)
- **Partitioning** : Par `ingestion_date` pour performance

#### 4. **Nettoyage Silver depuis Bronze**
- **Action** : "Nettoyage et structuration (Silver)"
- **Source** : Tables Bronze BigQuery
- **Orchestration** : Workflow DQ (Data Quality) via Dataform
- **Transformations** : D√©duplication, validation, typage
- **R√©sultat** : Tables/vues Silver dans BigQuery

#### 5. **Transformation Gold Business**
- **Action** : "Transformations et alimentation mod√®le Business (Gold)"
- **Source** : Tables Silver BigQuery
- **Orchestration** : Workflow MOM (Master Object Model) via Dataform
- **Transformations** : Enrichissement, agr√©gations, r√®gles m√©tier
- **R√©sultat** : Tables Gold optimis√©es pr√™tes pour analytics

### Services GCP Impliqu√©s

**üéº Cloud Composer (Orchestration)**
- Workflow global s√©quentiel
- Gestion des d√©pendances entre √©tapes
- Retry et gestion d'erreurs
- Scheduling et monitoring

**üìä Dataform (ELT Processing)**
- Workflow DQ pour la couche Silver
- Workflow MOM pour la couche Gold
- Gestion du lineage des transformations
- Interface graphique de visualisation

**üóÑÔ∏è BigQuery (Processing & Storage)**
- Requ√™tes d'ingestion (Bronze ‚Üí Silver)
- Requ√™tes DQ (Data Quality)
- Requ√™tes Transfo/Alim (Silver ‚Üí Gold)
- Tables externes et mat√©rialis√©es

**‚òÅÔ∏è Cloud Storage (Data Lake)**
- Couche Bronze : Stockage brut
- Stockage des fichiers sources
- Int√©gration native avec BigQuery

**üì° Pub/Sub (Events & Monitoring)**
- √âv√©nements + Logs + Notifications
- Monitoring en temps r√©el
- Alerting en cas d'√©chec

## Avantages de l'Architecture M√©daillon GCP

### üöÄ **Performance et Scalabilit√©**
- **Architecture m√©daillon √©prouv√©e** : Standard industrie pour les data lakes
- **Full BigQuery** : Traitement natif sans infrastructure externe
- **Transformations internes** : Flux Bronze ‚Üí Silver ‚Üí Gold enti√®rement dans BigQuery
- **Optimisations automatiques** : Partitioning, clustering, compression BigQuery

### üîç **Observabilit√© et Gouvernance**
- **Lineage complet** : Tra√ßabilit√© Bronze ‚Üí Silver ‚Üí Gold via Dataform
- **Monitoring applicatif int√©gr√©** : Pub/Sub pour √©v√©nements et notifications
- **Workflows visuels** : Interface Dataform pour visualisation des d√©pendances
- **Logs centralis√©s** : Tous les traitements trac√©s dans GCP

### üîß **Flexibilit√© et Maintenabilit√©**
- **S√©paration des responsabilit√©s** : Chaque couche a un r√¥le pr√©cis
- **Workflows orchestr√©s** : Cloud Composer pour gestion complexe
- **Pattern reproductible** : Template r√©utilisable pour nouveaux cas d'usage
- **√âvolutivit√©** : Ajout de nouvelles transformations facilit√©

## Cas d'Usage Support√©s par l'Architecture

### üìä **Volumes de Donn√©es Test√©s**
- ‚úÖ **5MB** : Tests et d√©veloppement, prototypage rapide
- ‚úÖ **1GB** : Datasets moyens, analytics d√©partementaux
- ‚úÖ **5GB** : Volumes importants, production entreprise
- ‚úÖ **>5GB** : Architecture scalable, splitting automatique possible

### üìÅ **Formats Sources (Couche Bronze)**
- **CSV** : D√©limiteurs configurables (`;`, `,`, `|`, `\t`)
- **JSON** : Structures imbriqu√©es, arrays, objets complexes
- **Parquet** : Format optimis√© pour analytics, compression native
- **Avro** : Schemas √©volutifs, int√©gration Kafka/Pub/Sub
- **Multi-formats** : Support simultan√© dans le m√™me pipeline

### ‚è∞ **Patterns Temporels d'Ingestion**
- **Batch quotidien** : Standard pour la plupart des cas d'usage
- **Intraday** : Plusieurs ex√©cutions par jour (H+2, H+6, etc.)
- **Near real-time** : D√©clenchement par √©v√©nements GCS via Cloud Functions
- **Micro-batch** : Traitement par petits lots avec Dataform scheduling

## √âvolutions et Patterns Avanc√©s

### üéØ **Pattern 1 Actuel : Ingestion CSV M√©daillon**
- ‚úÖ **Impl√©ment√©** : Workflow Cloud Composer complet
- ‚úÖ **RAW** : Cloud Storage landing zone temporaire
- ‚úÖ **Bronze** : BigQuery avec m√©tadonn√©es d'ingestion
- ‚úÖ **Silver** : BigQuery tables nettoy√©es et valid√©es
- ‚úÖ **Gold** : BigQuery tables mat√©rialis√©es business-ready
- ‚úÖ **Orchestration** : Dataform pour DQ et transformations

### üöÄ **Pattern 2 : Multi-Sources Enterprise**
- **Sources diverses** : APIs REST, bases relationnelles, SaaS
- **Connecteurs natifs** : Salesforce, SAP, Oracle via Cloud Data Fusion
- **CDC** : Change Data Capture pour r√©plication temps r√©el
- **Unified Bronze** : Consolidation multi-sources dans GCS

### ‚ö° **Pattern 3 : Streaming Temps R√©el**
- **Ingestion** : Cloud Pub/Sub ‚Üí Dataflow ‚Üí BigQuery
- **Architecture** : Lambda avec batch et streaming
- **Use cases** : IoT, logs applicatifs, √©v√©nements business
- **Fen√™trage** : Agr√©gations temps r√©el avec Apache Beam

### üåê **Pattern 4 : Data Mesh et F√©d√©ration**
- **Domaines m√©tier** : Datasets s√©par√©s par domain
- **Gouvernance d√©centralis√©e** : √âquipes propri√©taires de leurs donn√©es
- **APIs data** : Exposition via BigQuery views et Data Catalog
- **Cross-domain** : Lineage et discovery centralis√©s

## Correspondance avec le Framework de R√©f√©rence

Cette architecture m√©daillon **√©tendue 4-couches** correspond √† l'impl√©mentation GCP avanc√©e du framework de r√©f√©rence :

| **M√©daillon** | **Framework** | **Technologie GCP** | **R√¥le** |
|---------------|---------------|---------------------|----------|
| üìÅ **RAW** | **Landing Zone** | Cloud Storage (temporaire) | Landing zone fichiers sources |
| ü•â **Bronze** | **RAW √©tendu** | BigQuery + M√©tadonn√©es | Historisation avec tra√ßabilit√© |
| ü•à **Silver** | **Cleaned Data** | BigQuery Tables/Vues | Nettoyage et structuration |
| ü•á **Gold** | **Business Data** | BigQuery Tables Mat√©rialis√©es | Analytics-ready, enrichi |

### **üÜï Nouvelles M√©tadonn√©es Bronze Obligatoires**

```sql
-- Schema Bronze type avec m√©tadonn√©es d'ingestion
CREATE TABLE `bronze_schema.employees` (
  -- Colonnes m√©tier (donn√©es sources)
  id INT64,
  nom STRING,
  prenom STRING,
  -- ... autres colonnes m√©tier

  -- M√©tadonn√©es d'ingestion (OBLIGATOIRES)
  ingestion_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP(),
  source_file STRING,
  file_hash STRING,
  batch_id STRING,
  raw_data STRING  -- JSON des donn√©es brutes si besoin
)
PARTITION BY DATE(ingestion_date)
CLUSTER BY source_file;
```

### ‚úÖ **Conformit√© Framework Stricte**

Cette documentation respecte int√©gralement les standards d√©finis dans [`framework.md`](../framework.md) :

- ‚úÖ **Stack technique GCP** : 100% services Google Cloud Platform
- ‚úÖ **Architecture 4-couches** : RAW ‚Üí Bronze ‚Üí Silver ‚Üí Gold
- ‚úÖ **Conventions m√©daillon** : Nomenclature standardis√©e par couche
- ‚úÖ **M√©tadonn√©es obligatoires** : `ingestion_date`, `source_file`, `file_hash`, `batch_id`
- ‚úÖ **Orchestration Dataform** : ELT natif avec lineage et observabilit√©
- ‚úÖ **Patterns √©volutifs** : Extension vers streaming et multi-sources possible
- ‚úÖ **Tra√ßabilit√© compl√®te** : Du fichier source aux donn√©es business

L'architecture m√©daillon apporte une **standardisation industrie** tout en respectant les **principes du framework GCP** pour garantir coh√©rence et √©volutivit√©.