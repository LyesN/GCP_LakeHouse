{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"title-cell"},"source":["#Ingestion CSV vers BigQuery - Version Minimaliste\n","\n","**Objectif** : Ex√©cuter simplement la requ√™te LOAD DATA du Tutoriel 1\n","\n","**Pr√©requis** :\n","- Table `lake-471013.lakehouse_employee_data.employees` cr√©√©e (Tutoriel 1)\n","- Fichier `employees_5mb.csv` upload√© dans GCS\n","- Permissions BigQuery et GCS"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"setup-cell","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757419997424,"user_tz":-120,"elapsed":10135,"user":{"displayName":"Lyes NADOUR","userId":"17228350632541809921"}},"outputId":"2bc53539-9cfd-49e9-b2a9-02f7db0b072e"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Installation termin√©e\n"]}],"source":["# Installation et imports\n","!pip install google-cloud-bigquery -q\n","\n","from google.cloud import bigquery\n","from google.colab import auth\n","import os\n","\n","print(\"‚úÖ Installation termin√©e\")"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"auth-cell","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757420027698,"user_tz":-120,"elapsed":15014,"user":{"displayName":"Lyes NADOUR","userId":"17228350632541809921"}},"outputId":"e71e8e6c-ea28-4ebb-8a58-8c4453bd28c0"},"outputs":[{"output_type":"stream","name":"stdout","text":[" -- Authentification en cours...\n","‚úÖ Authentifi√© sur le projet: lake-471013\n"]}],"source":["# Authentification Google Cloud\n","print(\" -- Authentification en cours...\")\n","auth.authenticate_user()\n","\n","# Configuration du projet\n","PROJECT_ID = \"lake-471013\"  # ‚ö†Ô∏è Modifiez si n√©cessaire\n","os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT_ID\n","\n","print(f\"‚úÖ Authentifi√© sur le projet: {PROJECT_ID}\")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"config-cell","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757420033072,"user_tz":-120,"elapsed":7,"user":{"displayName":"Lyes NADOUR","userId":"17228350632541809921"}},"outputId":"1ca1b3a4-b921-476b-e799-acdf5ce9ec5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["üìÅ Table cible: lake-471013.lakehouse_employee_data.employees\n","üìÑ Fichier source: gs://lakehouse-bucket-20250903/employees_5mb.csv\n","‚úÖ Client BigQuery initialis√©\n"]}],"source":["# Configuration des param√®tres\n","FULL_TABLE_ID = \"lake-471013.lakehouse_employee_data.employees\"\n","GCS_URI = \"gs://lakehouse-bucket-20250903/employees_5mb.csv\"\n","\n","print(f\"üìÅ Table cible: {FULL_TABLE_ID}\")\n","print(f\"üìÑ Fichier source: {GCS_URI}\")\n","\n","# Initialiser le client BigQuery\n","client = bigquery.Client(project=PROJECT_ID)\n","print(\"‚úÖ Client BigQuery initialis√©\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ingestion-cell","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757420039093,"user_tz":-120,"elapsed":7,"user":{"displayName":"Lyes NADOUR","userId":"17228350632541809921"}},"outputId":"7fdaf9cc-b10b-41d6-890f-a9609cf5ed59"},"outputs":[{"output_type":"stream","name":"stdout","text":["üìÑ Source: gs://lakehouse-bucket-20250903/employees_5mb.csv\n","üìÅ Destination: lake-471013.lakehouse_employee_data.employees\n"]}],"source":["# üöÄ REQU√äTE D'INGESTION PRINCIPALE\n","ingestion_query = f\"\"\"\n","-- Flux d'ingestion CSV vers BigQuery\n","-- Fichier source : employees\n","-- Table cible : employees_5mb.csv\n","-- Truncate avant bulk\n","\n","TRUNCATE TABLE `lake-471013.lakehouse_employee_data.employees`;\n","\n","LOAD DATA INTO `lake-471013.lakehouse_employee_data.employees`\n","(id INT64, nom STRING, prenom STRING, email STRING, age INT64, ville STRING,\n"," code_postal STRING, telephone STRING, salaire FLOAT64, departement STRING,\n"," date_embauche DATE, statut STRING, score FLOAT64, latitude FLOAT64,\n"," longitude FLOAT64, commentaire STRING, reference STRING, niveau STRING,\n"," categorie STRING, timestamp TIMESTAMP)\n","FROM FILES (\n","  format = 'CSV',\n","  field_delimiter = ';',\n","  skip_leading_rows = 1,\n","  uris = ['gs://lakehouse-bucket-20250903/employees_5mb.csv']\n",");\n","\"\"\"\n","print(f\"üìÑ Source: {GCS_URI}\")\n","print(f\"üìÅ Destination: {FULL_TABLE_ID}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"verify-cell","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757420051617,"user_tz":-120,"elapsed":587,"user":{"displayName":"Lyes NADOUR","userId":"17228350632541809921"}},"outputId":"0f07272e-4993-49fc-e4bf-0701b7f8c03f"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Table trouv√©e: employees\n","üìä Lignes actuelles: 18,100\n"]}],"source":["# V√©rification rapide de la table\n","try:\n","    table = client.get_table(FULL_TABLE_ID)\n","    print(f\"‚úÖ Table trouv√©e: {table.table_id}\")\n","    print(f\"üìä Lignes actuelles: {table.num_rows:,}\")\n","except Exception as e:\n","    print(f\"‚ùå Erreur: {str(e)}\")\n","    print(\"üí° Assurez-vous que la table existe (voir Tutoriel 1)\")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"execute-cell","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757420576863,"user_tz":-120,"elapsed":8049,"user":{"displayName":"Lyes NADOUR","userId":"17228350632541809921"}},"outputId":"f0259808-4351-4c75-9be7-c01320316b87"},"outputs":[{"output_type":"stream","name":"stdout","text":["üìä Lignes avant ingestion: 18,100\n","\n","‚è≥ Ingestion en cours...\n","\n","==================================================\n","‚úÖ INGESTION TERMIN√âE AVEC SUCC√àS!\n","==================================================\n","üìà Lignes avant:     18,100\n","üìà Lignes apr√®s:     18,100\n","üìÑ Fichier trait√©:   employees_5mb.csv\n"]}],"source":["# Ex√©cution de l'ingestion\n","try:\n","    # Compter les lignes avant\n","    count_before = client.query(f\"SELECT COUNT(*) as count FROM `{FULL_TABLE_ID}`\").result()\n","    rows_before = list(count_before)[0].count\n","    print(f\"üìä Lignes avant ingestion: {rows_before:,}\")\n","\n","    # Lancer l'ingestion\n","    print(\"\\n‚è≥ Ingestion en cours...\")\n","    job = client.query(ingestion_query)\n","    job.result()  # Attendre la fin\n","\n","    # Compter les lignes apr√®s\n","    count_after = client.query(f\"SELECT COUNT(*) as count FROM `{FULL_TABLE_ID}`\").result()\n","    rows_after = list(count_after)[0].count\n","\n","    # R√©sum√©\n","    new_rows = rows_after - rows_before\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"‚úÖ INGESTION TERMIN√âE AVEC SUCC√àS!\")\n","    print(\"=\"*50)\n","    print(f\"üìà Lignes avant:     {rows_before:,}\")\n","    print(f\"üìà Lignes apr√®s:     {rows_after:,}\")\n","    print(f\"üìÑ Fichier trait√©:   {GCS_URI.split('/')[-1]}\")\n","\n","except Exception as e:\n","    print(f\"\\n‚ùå ERREUR LORS DE L'INGESTION:\")\n","    print(f\"   {str(e)}\")\n","    print(\"\\nüí° V√©rifications sugg√©r√©es:\")\n","    print(\"   ‚Ä¢ Le fichier CSV existe-t-il dans GCS ?\")\n","    print(\"   ‚Ä¢ Les permissions sont-elles correctes ?\")\n","    print(\"   ‚Ä¢ La table de destination existe-t-elle ?\")"]}]}