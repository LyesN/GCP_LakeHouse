{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "BigQuery_CSV_Ingestion_Minimal.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title-cell"
      },
      "source": [
        "# üöÄ Ingestion CSV vers BigQuery - Version Minimaliste\n",
        "\n",
        "**Objectif** : Ex√©cuter simplement la requ√™te LOAD DATA du Tutoriel 1\n",
        "\n",
        "**Pr√©requis** : \n",
        "- Table `lake-471013.lakehouse_employee_data.employees` cr√©√©e (Tutoriel 1)\n",
        "- Fichier `employees_5mb.csv` upload√© dans GCS\n",
        "- Permissions BigQuery et GCS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup-cell"
      },
      "outputs": [],
      "source": [
        "# Installation et imports\n",
        "!pip install google-cloud-bigquery -q\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.colab import auth\n",
        "import os\n",
        "\n",
        "print(\"‚úÖ Installation termin√©e\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auth-cell"
      },
      "outputs": [],
      "source": [
        "# Authentification Google Cloud\n",
        "print(\"üîê Authentification en cours...\")\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Configuration du projet\n",
        "PROJECT_ID = \"lake-471013\"  # ‚ö†Ô∏è Modifiez si n√©cessaire\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT_ID\n",
        "\n",
        "print(f\"‚úÖ Authentifi√© sur le projet: {PROJECT_ID}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config-cell"
      },
      "outputs": [],
      "source": [
        "# Configuration des param√®tres\n",
        "FULL_TABLE_ID = \"lake-471013.lakehouse_employee_data.employees\"\n",
        "GCS_URI = \"gs://lakehouse-bucket-20250903/employees_5mb.csv\"\n",
        "\n",
        "print(f\"üìÅ Table cible: {FULL_TABLE_ID}\")\n",
        "print(f\"üìÑ Fichier source: {GCS_URI}\")\n",
        "\n",
        "# Initialiser le client BigQuery\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "print(\"‚úÖ Client BigQuery initialis√©\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "verify-cell"
      },
      "outputs": [],
      "source": [
        "# V√©rification rapide de la table\n",
        "try:\n",
        "    table = client.get_table(FULL_TABLE_ID)\n",
        "    print(f\"‚úÖ Table trouv√©e: {table.table_id}\")\n",
        "    print(f\"üìä Lignes actuelles: {table.num_rows:,}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erreur: {str(e)}\")\n",
        "    print(\"üí° Assurez-vous que la table existe (voir Tutoriel 1)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ingestion-cell"
      },
      "outputs": [],
      "source": [
        "# üöÄ REQU√äTE D'INGESTION PRINCIPALE\n",
        "ingestion_query = f\"\"\"\n",
        "-- Flux d'ingestion principal depuis GCS avec sch√©ma forc√©\n",
        "LOAD DATA INTO `{FULL_TABLE_ID}`\n",
        "(id INT64, nom STRING, prenom STRING, email STRING, age INT64, ville STRING, \n",
        " code_postal STRING, telephone STRING, salaire FLOAT64, departement STRING, \n",
        " date_embauche DATE, statut STRING, score FLOAT64, latitude FLOAT64, \n",
        " longitude FLOAT64, commentaire STRING, reference STRING, niveau STRING, \n",
        " categorie STRING, timestamp TIMESTAMP)\n",
        "FROM FILES (\n",
        "  format = 'CSV',\n",
        "  field_delimiter = ';',\n",
        "  skip_leading_rows = 1,\n",
        "  uris = ['{GCS_URI}']\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "print(\"üöÄ Lancement de l'ingestion...\")\n",
        "print(f\"üìÑ Source: {GCS_URI}\")\n",
        "print(f\"üìÅ Destination: {FULL_TABLE_ID}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "execute-cell"
      },
      "outputs": [],
      "source": [
        "# Ex√©cution de l'ingestion\n",
        "try:\n",
        "    # Compter les lignes avant\n",
        "    count_before = client.query(f\"SELECT COUNT(*) as count FROM `{FULL_TABLE_ID}`\").result()\n",
        "    rows_before = list(count_before)[0].count\n",
        "    print(f\"üìä Lignes avant ingestion: {rows_before:,}\")\n",
        "    \n",
        "    # Lancer l'ingestion\n",
        "    print(\"\\n‚è≥ Ingestion en cours...\")\n",
        "    job = client.query(ingestion_query)\n",
        "    job.result()  # Attendre la fin\n",
        "    \n",
        "    # Compter les lignes apr√®s\n",
        "    count_after = client.query(f\"SELECT COUNT(*) as count FROM `{FULL_TABLE_ID}`\").result()\n",
        "    rows_after = list(count_after)[0].count\n",
        "    \n",
        "    # R√©sum√©\n",
        "    new_rows = rows_after - rows_before\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"‚úÖ INGESTION TERMIN√âE AVEC SUCC√àS!\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"üìà Lignes avant:     {rows_before:,}\")\n",
        "    print(f\"üìà Lignes apr√®s:     {rows_after:,}\")\n",
        "    print(f\"‚ûï Nouvelles lignes: {new_rows:,}\")\n",
        "    print(f\"üìÑ Fichier trait√©:   {GCS_URI.split('/')[-1]}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå ERREUR LORS DE L'INGESTION:\")\n",
        "    print(f\"   {str(e)}\")\n",
        "    print(\"\\nüí° V√©rifications sugg√©r√©es:\")\n",
        "    print(\"   ‚Ä¢ Le fichier CSV existe-t-il dans GCS ?\")\n",
        "    print(\"   ‚Ä¢ Les permissions sont-elles correctes ?\")\n",
        "    print(\"   ‚Ä¢ La table de destination existe-t-elle ?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "verification-cell"
      },
      "outputs": [],
      "source": [
        "# V√©rification finale - √âchantillon des donn√©es\n",
        "print(\"üîç V√©rification des donn√©es ing√©r√©es:\")\n",
        "\n",
        "sample_query = f\"\"\"\n",
        "SELECT \n",
        "    id, nom, prenom, email, departement, salaire, age\n",
        "FROM `{FULL_TABLE_ID}` \n",
        "ORDER BY id \n",
        "LIMIT 5\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    result = client.query(sample_query).result()\n",
        "    df = result.to_dataframe()\n",
        "    \n",
        "    print(\"\\nüìä √âchantillon des 5 premiers enregistrements:\")\n",
        "    display(df)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erreur lors de la v√©rification: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion-cell"
      },
      "source": [
        "## ‚úÖ Ingestion Termin√©e!\n",
        "\n",
        "Votre fichier CSV a √©t√© ing√©r√© avec succ√®s dans BigQuery.\n",
        "\n",
        "### Prochaines √©tapes:\n",
        "- Consultez le **Tutoriel 2** pour l'automatisation Python\n",
        "- Explorez le **Tutoriel 3 complet** pour les analyses avanc√©es\n",
        "- Impl√©mentez l'orchestration avec **Airflow** (Tutoriel 4)\n",
        "\n",
        "### Liens utiles:\n",
        "- [BigQuery Console](https://console.cloud.google.com/bigquery)\n",
        "- [Documentation LOAD DATA](https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv)\n"
      ]
    }
  ]
}